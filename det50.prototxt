layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn0"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "bn0_scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "pooling0"
  type: "Pooling"
  bottom: "conv0"
  top: "pooling0"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "stage1_unit1_conv1"
  type: "Convolution"
  bottom: "pooling0"
  top: "stage1_unit1_conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit1_bn1_scale"
  type: "Scale"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit1_relu1"
  type: "ReLU"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
}
layer {
  name: "stage1_unit1_conv2"
  type: "Convolution"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage1_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit1_bn2_scale"
  type: "Scale"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit1_relu2"
  type: "ReLU"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
}
layer {
  name: "stage1_unit1_conv3"
  type: "Convolution"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit1_bn3_scale"
  type: "Scale"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit1_conv1sc"
  type: "Convolution"
  bottom: "pooling0"
  top: "stage1_unit1_conv1sc"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit1_sc"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv1sc"
  top: "stage1_unit1_conv1sc"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit1_sc_scale"
  type: "Scale"
  bottom: "stage1_unit1_conv1sc"
  top: "stage1_unit1_conv1sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus0"
  type: "Eltwise"
  bottom: "stage1_unit1_conv3"
  bottom: "stage1_unit1_conv1sc"
  top: "_plus0"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage1_unit1_relu3"
  type: "ReLU"
  bottom: "_plus0"
  top: "_plus0"
}
layer {
  name: "stage1_unit2_conv1"
  type: "Convolution"
  bottom: "_plus0"
  top: "stage1_unit2_conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit2_bn1_scale"
  type: "Scale"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit2_relu1"
  type: "ReLU"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
}
layer {
  name: "stage1_unit2_conv2"
  type: "Convolution"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage1_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit2_bn2_scale"
  type: "Scale"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit2_relu2"
  type: "ReLU"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
}
layer {
  name: "stage1_unit2_conv3"
  type: "Convolution"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv3"
  top: "stage1_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit2_bn3_scale"
  type: "Scale"
  bottom: "stage1_unit2_conv3"
  top: "stage1_unit2_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus1"
  type: "Eltwise"
  bottom: "stage1_unit2_conv3"
  bottom: "_plus0"
  top: "_plus1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage1_unit2_relu3"
  type: "ReLU"
  bottom: "_plus1"
  top: "_plus1"
}
layer {
  name: "stage1_unit3_conv1"
  type: "Convolution"
  bottom: "_plus1"
  top: "stage1_unit3_conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit3_bn1_scale"
  type: "Scale"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit3_relu1"
  type: "ReLU"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
}
layer {
  name: "stage1_unit3_conv2"
  type: "Convolution"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage1_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit3_bn2_scale"
  type: "Scale"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage1_unit3_relu2"
  type: "ReLU"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
}
layer {
  name: "stage1_unit3_conv3"
  type: "Convolution"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage1_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv3"
  top: "stage1_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage1_unit3_bn3_scale"
  type: "Scale"
  bottom: "stage1_unit3_conv3"
  top: "stage1_unit3_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus2"
  type: "Eltwise"
  bottom: "stage1_unit3_conv3"
  bottom: "_plus1"
  top: "_plus2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage1_unit3_relu3"
  type: "ReLU"
  bottom: "_plus2"
  top: "_plus2"
}
layer {
  name: "stage2_unit1_conv1"
  type: "Convolution"
  bottom: "_plus2"
  top: "stage2_unit1_conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit1_bn1_scale"
  type: "Scale"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit1_relu1"
  type: "ReLU"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
}
layer {
  name: "stage2_unit1_conv2"
  type: "Convolution"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    dilation: 1
  }
}
layer {
  name: "stage2_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit1_bn2_scale"
  type: "Scale"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit1_relu2"
  type: "ReLU"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
}
layer {
  name: "stage2_unit1_conv3"
  type: "Convolution"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv3"
  top: "stage2_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit1_bn3_scale"
  type: "Scale"
  bottom: "stage2_unit1_conv3"
  top: "stage2_unit1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit1_conv1sc"
  type: "Convolution"
  bottom: "_plus2"
  top: "stage2_unit1_conv1sc"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "stage2_unit1_sc"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv1sc"
  top: "stage2_unit1_conv1sc"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit1_sc_scale"
  type: "Scale"
  bottom: "stage2_unit1_conv1sc"
  top: "stage2_unit1_conv1sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus3"
  type: "Eltwise"
  bottom: "stage2_unit1_conv3"
  bottom: "stage2_unit1_conv1sc"
  top: "_plus3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage2_unit1_relu3"
  type: "ReLU"
  bottom: "_plus3"
  top: "_plus3"
}
layer {
  name: "stage2_unit2_conv1"
  type: "Convolution"
  bottom: "_plus3"
  top: "stage2_unit2_conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit2_bn1_scale"
  type: "Scale"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit2_relu1"
  type: "ReLU"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
}
layer {
  name: "stage2_unit2_conv2"
  type: "Convolution"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage2_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit2_bn2_scale"
  type: "Scale"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit2_relu2"
  type: "ReLU"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
}
layer {
  name: "stage2_unit2_conv3"
  type: "Convolution"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv3"
  top: "stage2_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit2_bn3_scale"
  type: "Scale"
  bottom: "stage2_unit2_conv3"
  top: "stage2_unit2_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus4"
  type: "Eltwise"
  bottom: "stage2_unit2_conv3"
  bottom: "_plus3"
  top: "_plus4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage2_unit2_relu3"
  type: "ReLU"
  bottom: "_plus4"
  top: "_plus4"
}
layer {
  name: "stage2_unit3_conv1"
  type: "Convolution"
  bottom: "_plus4"
  top: "stage2_unit3_conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit3_bn1_scale"
  type: "Scale"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit3_relu1"
  type: "ReLU"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
}
layer {
  name: "stage2_unit3_conv2"
  type: "Convolution"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage2_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit3_bn2_scale"
  type: "Scale"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit3_relu2"
  type: "ReLU"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
}
layer {
  name: "stage2_unit3_conv3"
  type: "Convolution"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv3"
  top: "stage2_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit3_bn3_scale"
  type: "Scale"
  bottom: "stage2_unit3_conv3"
  top: "stage2_unit3_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus5"
  type: "Eltwise"
  bottom: "stage2_unit3_conv3"
  bottom: "_plus4"
  top: "_plus5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage2_unit3_relu3"
  type: "ReLU"
  bottom: "_plus5"
  top: "_plus5"
}
layer {
  name: "stage2_unit4_conv1"
  type: "Convolution"
  bottom: "_plus5"
  top: "stage2_unit4_conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit4_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit4_bn1_scale"
  type: "Scale"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit4_relu1"
  type: "ReLU"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
}
layer {
  name: "stage2_unit4_conv2"
  type: "Convolution"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage2_unit4_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit4_bn2_scale"
  type: "Scale"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage2_unit4_relu2"
  type: "ReLU"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
}
layer {
  name: "stage2_unit4_conv3"
  type: "Convolution"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage2_unit4_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv3"
  top: "stage2_unit4_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage2_unit4_bn3_scale"
  type: "Scale"
  bottom: "stage2_unit4_conv3"
  top: "stage2_unit4_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus6"
  type: "Eltwise"
  bottom: "stage2_unit4_conv3"
  bottom: "_plus5"
  top: "_plus6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage2_unit4_relu3"
  type: "ReLU"
  bottom: "_plus6"
  top: "_plus6"
}
layer {
  name: "stage3_unit1_conv1"
  type: "Convolution"
  bottom: "_plus6"
  top: "stage3_unit1_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit1_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit1_relu1"
  type: "ReLU"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
}
layer {
  name: "stage3_unit1_conv2"
  type: "Convolution"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    dilation: 1
  }
}
layer {
  name: "stage3_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit1_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit1_relu2"
  type: "ReLU"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
}
layer {
  name: "stage3_unit1_conv3"
  type: "Convolution"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv3"
  top: "stage3_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit1_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit1_conv3"
  top: "stage3_unit1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit1_conv1sc"
  type: "Convolution"
  bottom: "_plus6"
  top: "stage3_unit1_conv1sc"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "stage3_unit1_sc"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv1sc"
  top: "stage3_unit1_conv1sc"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit1_sc_scale"
  type: "Scale"
  bottom: "stage3_unit1_conv1sc"
  top: "stage3_unit1_conv1sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus7"
  type: "Eltwise"
  bottom: "stage3_unit1_conv3"
  bottom: "stage3_unit1_conv1sc"
  top: "_plus7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit1_relu3"
  type: "ReLU"
  bottom: "_plus7"
  top: "_plus7"
}
layer {
  name: "stage3_unit2_conv1"
  type: "Convolution"
  bottom: "_plus7"
  top: "stage3_unit2_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit2_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit2_relu1"
  type: "ReLU"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
}
layer {
  name: "stage3_unit2_conv2"
  type: "Convolution"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage3_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit2_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit2_relu2"
  type: "ReLU"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
}
layer {
  name: "stage3_unit2_conv3"
  type: "Convolution"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv3"
  top: "stage3_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit2_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit2_conv3"
  top: "stage3_unit2_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus8"
  type: "Eltwise"
  bottom: "stage3_unit2_conv3"
  bottom: "_plus7"
  top: "_plus8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit2_relu3"
  type: "ReLU"
  bottom: "_plus8"
  top: "_plus8"
}
layer {
  name: "stage3_unit3_conv1"
  type: "Convolution"
  bottom: "_plus8"
  top: "stage3_unit3_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit3_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit3_relu1"
  type: "ReLU"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
}
layer {
  name: "stage3_unit3_conv2"
  type: "Convolution"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage3_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit3_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit3_relu2"
  type: "ReLU"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
}
layer {
  name: "stage3_unit3_conv3"
  type: "Convolution"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv3"
  top: "stage3_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit3_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit3_conv3"
  top: "stage3_unit3_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus9"
  type: "Eltwise"
  bottom: "stage3_unit3_conv3"
  bottom: "_plus8"
  top: "_plus9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit3_relu3"
  type: "ReLU"
  bottom: "_plus9"
  top: "_plus9"
}
layer {
  name: "stage3_unit4_conv1"
  type: "Convolution"
  bottom: "_plus9"
  top: "stage3_unit4_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit4_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit4_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit4_relu1"
  type: "ReLU"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
}
layer {
  name: "stage3_unit4_conv2"
  type: "Convolution"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage3_unit4_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit4_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit4_relu2"
  type: "ReLU"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
}
layer {
  name: "stage3_unit4_conv3"
  type: "Convolution"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit4_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv3"
  top: "stage3_unit4_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit4_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit4_conv3"
  top: "stage3_unit4_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus10"
  type: "Eltwise"
  bottom: "stage3_unit4_conv3"
  bottom: "_plus9"
  top: "_plus10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit4_relu3"
  type: "ReLU"
  bottom: "_plus10"
  top: "_plus10"
}
layer {
  name: "stage3_unit5_conv1"
  type: "Convolution"
  bottom: "_plus10"
  top: "stage3_unit5_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit5_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit5_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit5_relu1"
  type: "ReLU"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
}
layer {
  name: "stage3_unit5_conv2"
  type: "Convolution"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage3_unit5_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit5_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit5_relu2"
  type: "ReLU"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
}
layer {
  name: "stage3_unit5_conv3"
  type: "Convolution"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit5_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv3"
  top: "stage3_unit5_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit5_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit5_conv3"
  top: "stage3_unit5_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus11"
  type: "Eltwise"
  bottom: "stage3_unit5_conv3"
  bottom: "_plus10"
  top: "_plus11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit5_relu3"
  type: "ReLU"
  bottom: "_plus11"
  top: "_plus11"
}
layer {
  name: "stage3_unit6_conv1"
  type: "Convolution"
  bottom: "_plus11"
  top: "stage3_unit6_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit6_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit6_bn1_scale"
  type: "Scale"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit6_relu1"
  type: "ReLU"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
}
layer {
  name: "stage3_unit6_conv2"
  type: "Convolution"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "stage3_unit6_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit6_bn2_scale"
  type: "Scale"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage3_unit6_relu2"
  type: "ReLU"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
}
layer {
  name: "stage3_unit6_conv3"
  type: "Convolution"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage3_unit6_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv3"
  top: "stage3_unit6_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage3_unit6_bn3_scale"
  type: "Scale"
  bottom: "stage3_unit6_conv3"
  top: "stage3_unit6_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus12"
  type: "Eltwise"
  bottom: "stage3_unit6_conv3"
  bottom: "_plus11"
  top: "_plus12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage3_unit6_relu3"
  type: "ReLU"
  bottom: "_plus12"
  top: "_plus12"
}
layer {
  name: "stage4_unit1_conv1"
  type: "Convolution"
  bottom: "_plus12"
  top: "stage4_unit1_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit1_bn1_scale"
  type: "Scale"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit1_relu1"
  type: "ReLU"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
}
layer {
  name: "stage4_unit1_conv2"
  type: "Convolution"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage4_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit1_bn2_scale"
  type: "Scale"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit1_relu2"
  type: "ReLU"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
}
layer {
  name: "stage4_unit1_conv3"
  type: "Convolution"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv3"
  top: "stage4_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit1_bn3_scale"
  type: "Scale"
  bottom: "stage4_unit1_conv3"
  top: "stage4_unit1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit1_conv1sc"
  type: "Convolution"
  bottom: "_plus12"
  top: "stage4_unit1_conv1sc"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit1_sc"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv1sc"
  top: "stage4_unit1_conv1sc"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit1_sc_scale"
  type: "Scale"
  bottom: "stage4_unit1_conv1sc"
  top: "stage4_unit1_conv1sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus13"
  type: "Eltwise"
  bottom: "stage4_unit1_conv3"
  bottom: "stage4_unit1_conv1sc"
  top: "_plus13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage4_unit1_relu3"
  type: "ReLU"
  bottom: "_plus13"
  top: "_plus13"
}
layer {
  name: "stage4_unit2_conv1"
  type: "Convolution"
  bottom: "_plus13"
  top: "stage4_unit2_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit2_bn1_scale"
  type: "Scale"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit2_relu1"
  type: "ReLU"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
}
layer {
  name: "stage4_unit2_conv2"
  type: "Convolution"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage4_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit2_bn2_scale"
  type: "Scale"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit2_relu2"
  type: "ReLU"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
}
layer {
  name: "stage4_unit2_conv3"
  type: "Convolution"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv3"
  top: "stage4_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit2_bn3_scale"
  type: "Scale"
  bottom: "stage4_unit2_conv3"
  top: "stage4_unit2_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus14"
  type: "Eltwise"
  bottom: "stage4_unit2_conv3"
  bottom: "_plus13"
  top: "_plus14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage4_unit2_relu3"
  type: "ReLU"
  bottom: "_plus14"
  top: "_plus14"
}
layer {
  name: "stage4_unit3_conv1"
  type: "Convolution"
  bottom: "_plus14"
  top: "stage4_unit3_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit3_bn1_scale"
  type: "Scale"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit3_relu1"
  type: "ReLU"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
}
layer {
  name: "stage4_unit3_conv2"
  type: "Convolution"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage4_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit3_bn2_scale"
  type: "Scale"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage4_unit3_relu2"
  type: "ReLU"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
}
layer {
  name: "stage4_unit3_conv3"
  type: "Convolution"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage4_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv3"
  top: "stage4_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage4_unit3_bn3_scale"
  type: "Scale"
  bottom: "stage4_unit3_conv3"
  top: "stage4_unit3_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus15"
  type: "Eltwise"
  bottom: "stage4_unit3_conv3"
  bottom: "_plus14"
  top: "_plus15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage4_unit3_relu3"
  type: "ReLU"
  bottom: "_plus15"
  top: "_plus15"
}
layer {
  name: "stage5_unit1_conv1"
  type: "Convolution"
  bottom: "_plus15"
  top: "stage5_unit1_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage5_unit1_conv1"
  top: "stage5_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit1_bn1_scale"
  type: "Scale"
  bottom: "stage5_unit1_conv1"
  top: "stage5_unit1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit1_relu1"
  type: "ReLU"
  bottom: "stage5_unit1_conv1"
  top: "stage5_unit1_conv1"
}
layer {
  name: "stage5_unit1_conv2"
  type: "Convolution"
  bottom: "stage5_unit1_conv1"
  top: "stage5_unit1_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage5_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage5_unit1_conv2"
  top: "stage5_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit1_bn2_scale"
  type: "Scale"
  bottom: "stage5_unit1_conv2"
  top: "stage5_unit1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit1_relu2"
  type: "ReLU"
  bottom: "stage5_unit1_conv2"
  top: "stage5_unit1_conv2"
}
layer {
  name: "stage5_unit1_conv3"
  type: "Convolution"
  bottom: "stage5_unit1_conv2"
  top: "stage5_unit1_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage5_unit1_conv3"
  top: "stage5_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit1_bn3_scale"
  type: "Scale"
  bottom: "stage5_unit1_conv3"
  top: "stage5_unit1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit1_conv1sc"
  type: "Convolution"
  bottom: "_plus15"
  top: "stage5_unit1_conv1sc"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit1_sc"
  type: "BatchNorm"
  bottom: "stage5_unit1_conv1sc"
  top: "stage5_unit1_conv1sc"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit1_sc_scale"
  type: "Scale"
  bottom: "stage5_unit1_conv1sc"
  top: "stage5_unit1_conv1sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus16"
  type: "Eltwise"
  bottom: "stage5_unit1_conv3"
  bottom: "stage5_unit1_conv1sc"
  top: "_plus16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage5_unit1_relu3"
  type: "ReLU"
  bottom: "_plus16"
  top: "_plus16"
}
layer {
  name: "stage5_unit2_conv1"
  type: "Convolution"
  bottom: "_plus16"
  top: "stage5_unit2_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage5_unit2_conv1"
  top: "stage5_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit2_bn1_scale"
  type: "Scale"
  bottom: "stage5_unit2_conv1"
  top: "stage5_unit2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit2_relu1"
  type: "ReLU"
  bottom: "stage5_unit2_conv1"
  top: "stage5_unit2_conv1"
}
layer {
  name: "stage5_unit2_conv2"
  type: "Convolution"
  bottom: "stage5_unit2_conv1"
  top: "stage5_unit2_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage5_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage5_unit2_conv2"
  top: "stage5_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit2_bn2_scale"
  type: "Scale"
  bottom: "stage5_unit2_conv2"
  top: "stage5_unit2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit2_relu2"
  type: "ReLU"
  bottom: "stage5_unit2_conv2"
  top: "stage5_unit2_conv2"
}
layer {
  name: "stage5_unit2_conv3"
  type: "Convolution"
  bottom: "stage5_unit2_conv2"
  top: "stage5_unit2_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage5_unit2_conv3"
  top: "stage5_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit2_bn3_scale"
  type: "Scale"
  bottom: "stage5_unit2_conv3"
  top: "stage5_unit2_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus17"
  type: "Eltwise"
  bottom: "stage5_unit2_conv3"
  bottom: "_plus16"
  top: "_plus17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage5_unit2_relu3"
  type: "ReLU"
  bottom: "_plus17"
  top: "_plus17"
}
layer {
  name: "stage5_unit3_conv1"
  type: "Convolution"
  bottom: "_plus17"
  top: "stage5_unit3_conv1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage5_unit3_conv1"
  top: "stage5_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit3_bn1_scale"
  type: "Scale"
  bottom: "stage5_unit3_conv1"
  top: "stage5_unit3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit3_relu1"
  type: "ReLU"
  bottom: "stage5_unit3_conv1"
  top: "stage5_unit3_conv1"
}
layer {
  name: "stage5_unit3_conv2"
  type: "Convolution"
  bottom: "stage5_unit3_conv1"
  top: "stage5_unit3_conv2"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "stage5_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage5_unit3_conv2"
  top: "stage5_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit3_bn2_scale"
  type: "Scale"
  bottom: "stage5_unit3_conv2"
  top: "stage5_unit3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "stage5_unit3_relu2"
  type: "ReLU"
  bottom: "stage5_unit3_conv2"
  top: "stage5_unit3_conv2"
}
layer {
  name: "stage5_unit3_conv3"
  type: "Convolution"
  bottom: "stage5_unit3_conv2"
  top: "stage5_unit3_conv3"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "stage5_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage5_unit3_conv3"
  top: "stage5_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  name: "stage5_unit3_bn3_scale"
  type: "Scale"
  bottom: "stage5_unit3_conv3"
  top: "stage5_unit3_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "_plus18"
  type: "Eltwise"
  bottom: "stage5_unit3_conv3"
  bottom: "_plus17"
  top: "_plus18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "stage5_unit3_relu3"
  type: "ReLU"
  bottom: "_plus18"
  top: "_plus18"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "_plus18"
  top: "pool1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "fc1"
  inner_product_param {
    num_output: 1000
  }
}

layer {
  name: "softmax"
  type: "Softmax"
  bottom: "fc1"
  top: "softmax"
}
